{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport torch\nfrom torch import nn\nfrom torch.nn import functional as F\nimport os\nfrom os import path\nfrom matplotlib import pyplot as plt\nfrom torchinfo import summary\nfrom torchmetrics.classification import MulticlassAccuracy\n\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nprint(device)\n\nos.environ[\"TOKENIZERS_PARALLELISM\"] = \"true\"\nfrom tokenizers import ByteLevelBPETokenizer","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-08-18T20:54:30.699951Z","iopub.execute_input":"2023-08-18T20:54:30.700352Z","iopub.status.idle":"2023-08-18T20:54:48.071752Z","shell.execute_reply.started":"2023-08-18T20:54:30.700319Z","shell.execute_reply":"2023-08-18T20:54:48.070602Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n  warnings.warn(f\"file system plugins are not loaded: {e}\")\n","output_type":"stream"},{"name":"stdout","text":"cpu\n","output_type":"stream"}]},{"cell_type":"code","source":"import importlib.util\nlightning = importlib.util.find_spec(\"lightning\")\nif lightning is None:\n    !pip install lightning\n#\nimport lightning.pytorch as pl","metadata":{"execution":{"iopub.status.busy":"2023-08-18T20:54:48.076230Z","iopub.execute_input":"2023-08-18T20:54:48.076622Z","iopub.status.idle":"2023-08-18T20:55:11.047184Z","shell.execute_reply.started":"2023-08-18T20:54:48.076589Z","shell.execute_reply":"2023-08-18T20:55:11.045970Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Collecting lightning\n  Downloading lightning-2.0.7-py3-none-any.whl (1.9 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m25.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: Jinja2<5.0 in /opt/conda/lib/python3.10/site-packages (from lightning) (3.1.2)\nRequirement already satisfied: PyYAML<8.0 in /opt/conda/lib/python3.10/site-packages (from lightning) (6.0)\nRequirement already satisfied: arrow<3.0,>=1.2.0 in /opt/conda/lib/python3.10/site-packages (from lightning) (1.2.3)\nRequirement already satisfied: backoff<4.0,>=2.2.1 in /opt/conda/lib/python3.10/site-packages (from lightning) (2.2.1)\nRequirement already satisfied: beautifulsoup4<6.0,>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from lightning) (4.12.2)\nRequirement already satisfied: click<10.0 in /opt/conda/lib/python3.10/site-packages (from lightning) (8.1.3)\nCollecting croniter<1.5.0,>=1.3.0 (from lightning)\n  Downloading croniter-1.4.1-py2.py3-none-any.whl (19 kB)\nCollecting dateutils<2.0 (from lightning)\n  Downloading dateutils-0.6.12-py2.py3-none-any.whl (5.7 kB)\nCollecting deepdiff<8.0,>=5.7.0 (from lightning)\n  Downloading deepdiff-6.3.1-py3-none-any.whl (70 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.7/70.7 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: fastapi<2.0,>=0.92.0 in /opt/conda/lib/python3.10/site-packages (from lightning) (0.98.0)\nRequirement already satisfied: fsspec<2025.0,>=2022.5.0 in /opt/conda/lib/python3.10/site-packages (from lightning) (2023.6.0)\nCollecting inquirer<5.0,>=2.10.0 (from lightning)\n  Downloading inquirer-3.1.3-py3-none-any.whl (18 kB)\nCollecting lightning-cloud>=0.5.37 (from lightning)\n  Downloading lightning_cloud-0.5.37-py3-none-any.whl (596 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m596.7/596.7 kB\u001b[0m \u001b[31m30.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: lightning-utilities<2.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from lightning) (0.9.0)\nRequirement already satisfied: numpy<3.0,>=1.17.2 in /opt/conda/lib/python3.10/site-packages (from lightning) (1.23.5)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from lightning) (21.3)\nRequirement already satisfied: psutil<7.0 in /opt/conda/lib/python3.10/site-packages (from lightning) (5.9.3)\nRequirement already satisfied: pydantic<2.2.0,>=1.7.4 in /opt/conda/lib/python3.10/site-packages (from lightning) (1.10.9)\nCollecting python-multipart<2.0,>=0.0.5 (from lightning)\n  Downloading python_multipart-0.0.6-py3-none-any.whl (45 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.7/45.7 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: requests<4.0 in /opt/conda/lib/python3.10/site-packages (from lightning) (2.31.0)\nRequirement already satisfied: rich<15.0,>=12.3.0 in /opt/conda/lib/python3.10/site-packages (from lightning) (13.4.2)\nRequirement already satisfied: starlette in /opt/conda/lib/python3.10/site-packages (from lightning) (0.27.0)\nCollecting starsessions<2.0,>=1.2.1 (from lightning)\n  Downloading starsessions-1.3.0-py3-none-any.whl (10 kB)\nRequirement already satisfied: torch<4.0,>=1.11.0 in /opt/conda/lib/python3.10/site-packages (from lightning) (2.0.0+cpu)\nRequirement already satisfied: torchmetrics<2.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from lightning) (1.0.0)\nRequirement already satisfied: tqdm<6.0,>=4.57.0 in /opt/conda/lib/python3.10/site-packages (from lightning) (4.65.0)\nRequirement already satisfied: traitlets<7.0,>=5.3.0 in /opt/conda/lib/python3.10/site-packages (from lightning) (5.9.0)\nRequirement already satisfied: typing-extensions<6.0,>=4.0.0 in /opt/conda/lib/python3.10/site-packages (from lightning) (4.6.3)\nRequirement already satisfied: urllib3<4.0 in /opt/conda/lib/python3.10/site-packages (from lightning) (1.26.15)\nRequirement already satisfied: uvicorn<2.0 in /opt/conda/lib/python3.10/site-packages (from lightning) (0.22.0)\nRequirement already satisfied: websocket-client<3.0 in /opt/conda/lib/python3.10/site-packages (from lightning) (1.6.0)\nRequirement already satisfied: websockets<13.0 in /opt/conda/lib/python3.10/site-packages (from lightning) (11.0.3)\nRequirement already satisfied: pytorch-lightning in /opt/conda/lib/python3.10/site-packages (from lightning) (2.0.4)\nRequirement already satisfied: python-dateutil>=2.7.0 in /opt/conda/lib/python3.10/site-packages (from arrow<3.0,>=1.2.0->lightning) (2.8.2)\nRequirement already satisfied: soupsieve>1.2 in /opt/conda/lib/python3.10/site-packages (from beautifulsoup4<6.0,>=4.8.0->lightning) (2.3.2.post1)\nRequirement already satisfied: pytz in /opt/conda/lib/python3.10/site-packages (from dateutils<2.0->lightning) (2023.3)\nCollecting ordered-set<4.2.0,>=4.0.2 (from deepdiff<8.0,>=5.7.0->lightning)\n  Downloading ordered_set-4.1.0-py3-none-any.whl (7.6 kB)\nRequirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /opt/conda/lib/python3.10/site-packages (from fsspec<2025.0,>=2022.5.0->lightning) (3.8.4)\nRequirement already satisfied: blessed>=1.19.0 in /opt/conda/lib/python3.10/site-packages (from inquirer<5.0,>=2.10.0->lightning) (1.20.0)\nCollecting python-editor>=1.0.4 (from inquirer<5.0,>=2.10.0->lightning)\n  Downloading python_editor-1.0.4-py3-none-any.whl (4.9 kB)\nCollecting readchar>=3.0.6 (from inquirer<5.0,>=2.10.0->lightning)\n  Downloading readchar-4.0.5-py3-none-any.whl (8.5 kB)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from Jinja2<5.0->lightning) (2.1.3)\nRequirement already satisfied: pyjwt in /opt/conda/lib/python3.10/site-packages (from lightning-cloud>=0.5.37->lightning) (2.7.0)\nRequirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from lightning-cloud>=0.5.37->lightning) (1.16.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->lightning) (3.0.9)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<4.0->lightning) (3.1.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<4.0->lightning) (3.4)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<4.0->lightning) (2023.5.7)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.10/site-packages (from rich<15.0,>=12.3.0->lightning) (2.2.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from rich<15.0,>=12.3.0->lightning) (2.15.1)\nRequirement already satisfied: anyio<5,>=3.4.0 in /opt/conda/lib/python3.10/site-packages (from starlette->lightning) (3.7.0)\nRequirement already satisfied: itsdangerous<3.0.0,>=2.0.1 in /opt/conda/lib/python3.10/site-packages (from starsessions<2.0,>=1.2.1->lightning) (2.1.2)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch<4.0,>=1.11.0->lightning) (3.12.2)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch<4.0,>=1.11.0->lightning) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch<4.0,>=1.11.0->lightning) (3.1)\nRequirement already satisfied: h11>=0.8 in /opt/conda/lib/python3.10/site-packages (from uvicorn<2.0->lightning) (0.14.0)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec<2025.0,>=2022.5.0->lightning) (23.1.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec<2025.0,>=2022.5.0->lightning) (6.0.4)\nRequirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec<2025.0,>=2022.5.0->lightning) (4.0.2)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec<2025.0,>=2022.5.0->lightning) (1.9.2)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec<2025.0,>=2022.5.0->lightning) (1.3.3)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec<2025.0,>=2022.5.0->lightning) (1.3.1)\nRequirement already satisfied: sniffio>=1.1 in /opt/conda/lib/python3.10/site-packages (from anyio<5,>=3.4.0->starlette->lightning) (1.3.0)\nRequirement already satisfied: exceptiongroup in /opt/conda/lib/python3.10/site-packages (from anyio<5,>=3.4.0->starlette->lightning) (1.1.1)\nRequirement already satisfied: wcwidth>=0.1.4 in /opt/conda/lib/python3.10/site-packages (from blessed>=1.19.0->inquirer<5.0,>=2.10.0->lightning) (0.2.6)\nRequirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich<15.0,>=12.3.0->lightning) (0.1.2)\nRequirement already satisfied: setuptools>=41.0 in /opt/conda/lib/python3.10/site-packages (from readchar>=3.0.6->inquirer<5.0,>=2.10.0->lightning) (59.8.0)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch<4.0,>=1.11.0->lightning) (1.3.0)\nInstalling collected packages: python-editor, readchar, python-multipart, ordered-set, inquirer, deepdiff, dateutils, croniter, starsessions, lightning-cloud, lightning\nSuccessfully installed croniter-1.4.1 dateutils-0.6.12 deepdiff-6.3.1 inquirer-3.1.3 lightning-2.0.7 lightning-cloud-0.5.37 ordered-set-4.1.0 python-editor-1.0.4 python-multipart-0.0.6 readchar-4.0.5 starsessions-1.3.0\n","output_type":"stream"}]},{"cell_type":"code","source":"checkpoints = {\n    \"lstm\": r'/kaggle/input/2-lstm-model-for-next-word-checking/lstm_mlit_best.pt',\n}\n\ndef load_from_checkpoint_if_possible(model, model_type):\n    if model_type in checkpoints:\n        model.load_state_dict(torch.load(checkpoints[model_type], map_location=model.device))\n        print(f\"Loaded {model_type} model from location: {checkpoints[model_type]}\")\n    #\n#","metadata":{"execution":{"iopub.status.busy":"2023-08-18T20:55:11.049312Z","iopub.execute_input":"2023-08-18T20:55:11.050579Z","iopub.status.idle":"2023-08-18T20:55:11.059918Z","shell.execute_reply.started":"2023-08-18T20:55:11.050527Z","shell.execute_reply":"2023-08-18T20:55:11.058760Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"def load_tokenizer(tok_dir):\n    # Load the tokenizer.\n    tok = ByteLevelBPETokenizer.from_file(\n        path.join(tok_dir, \"tok-vocab.json\"),\n        merges_filename=path.join(tok_dir, \"tok-merges.txt\"),\n    )\n    return tok\n#\n\nVOCAB_SIZE=6600\n\ntok = load_tokenizer(\n    tok_dir=f\"/kaggle/input/tok{VOCAB_SIZE}\",\n)\nprint(tok.get_vocab_size())\nassert tok.get_vocab_size() == VOCAB_SIZE","metadata":{"execution":{"iopub.status.busy":"2023-08-18T20:55:11.063128Z","iopub.execute_input":"2023-08-18T20:55:11.063459Z","iopub.status.idle":"2023-08-18T20:55:11.144553Z","shell.execute_reply.started":"2023-08-18T20:55:11.063423Z","shell.execute_reply":"2023-08-18T20:55:11.143272Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"6600\n","output_type":"stream"}]},{"cell_type":"code","source":"# Basic sanity checking of the tokenizer via visual inspection.\nenc = tok.encode(\"Hello Juliet! It was great meeting you yesterday for lunch. Let's meet again and finalize the deal next week.\")\nprint(enc)\nprint(enc.ids)\nprint(len(enc.ids))\nprint(enc.tokens)","metadata":{"execution":{"iopub.status.busy":"2023-08-18T20:55:11.146121Z","iopub.execute_input":"2023-08-18T20:55:11.146631Z","iopub.status.idle":"2023-08-18T20:55:11.171743Z","shell.execute_reply.started":"2023-08-18T20:55:11.146559Z","shell.execute_reply":"2023-08-18T20:55:11.170706Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Encoding(num_tokens=27, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing])\n[5491, 418, 5870, 2944, 2, 1101, 439, 950, 2479, 315, 5974, 313, 5896, 1, 380, 309, 489, 1351, 1017, 285, 2390, 1109, 264, 2000, 1249, 1078, 1]\n27\n['Hel', 'lo', 'ĠJul', 'iet', '!', 'ĠIt', 'Ġwas', 'Ġgreat', 'Ġmeeting', 'Ġyou', 'Ġyesterday', 'Ġfor', 'Ġlunch', '.', 'ĠL', 'et', \"'s\", 'Ġmeet', 'Ġagain', 'Ġand', 'Ġfinal', 'ize', 'Ġthe', 'Ġdeal', 'Ġnext', 'Ġweek', '.']\n","output_type":"stream"}]},{"cell_type":"code","source":"BATCH_SIZE=16 if device == 'cpu' else 64\nLIMIT=12 * 1000000\nSEQ_LEN=256","metadata":{"execution":{"iopub.status.busy":"2023-08-18T20:55:11.173085Z","iopub.execute_input":"2023-08-18T20:55:11.173999Z","iopub.status.idle":"2023-08-18T20:55:11.184283Z","shell.execute_reply.started":"2023-08-18T20:55:11.173955Z","shell.execute_reply":"2023-08-18T20:55:11.183439Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"class WordPredictionLSTMModel(nn.Module):\n    def __init__(self, num_embed, embed_dim, pad_idx, lstm_hidden_dim, lstm_num_layers, output_dim, dropout):\n        super().__init__()\n        self.vocab_size = num_embed\n        self.embed = nn.Embedding(num_embed, embed_dim, pad_idx)\n        self.lstm = nn.LSTM(embed_dim, lstm_hidden_dim, lstm_num_layers, batch_first=True, dropout=dropout)\n        self.fc = nn.Sequential(\n            nn.Linear(lstm_hidden_dim, lstm_hidden_dim * 4),\n            nn.LayerNorm(lstm_hidden_dim * 4),\n            nn.LeakyReLU(),\n            nn.Dropout(p=dropout),\n\n            nn.Linear(lstm_hidden_dim * 4, output_dim),\n        )\n    #\n    \n    def forward(self, x):\n        x = self.embed(x)\n        x, _ = self.lstm(x)\n        x = self.fc(x)\n        x = x.permute(0, 2, 1)\n        return x\n    #\n#\n\ndef test_model(model):\n    x = torch.randint(0, VOCAB_SIZE-1, (BATCH_SIZE, SEQ_LEN))\n\n    print(model.embed.weight.shape)\n    print(model.fc[-1].weight.shape)\n\n    y = model(x)\n    print(y.shape)\n\n    print(summary(model, input_size=x.shape, dtypes=[torch.long]))\n    del x, y\n#\n\nlstm_model = WordPredictionLSTMModel(\n    num_embed=VOCAB_SIZE, embed_dim=256, pad_idx=0, lstm_hidden_dim=1024, lstm_num_layers=4, output_dim=VOCAB_SIZE, dropout=0.5,\n)\ntest_model(lstm_model)\ndel lstm_model","metadata":{"execution":{"iopub.status.busy":"2023-08-18T20:55:11.187012Z","iopub.execute_input":"2023-08-18T20:55:11.188210Z","iopub.status.idle":"2023-08-18T20:55:23.052899Z","shell.execute_reply.started":"2023-08-18T20:55:11.188163Z","shell.execute_reply":"2023-08-18T20:55:23.051729Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"torch.Size([6600, 256])\ntorch.Size([6600, 4096])\ntorch.Size([16, 6600, 256])\n==========================================================================================\nLayer (type:depth-idx)                   Output Shape              Param #\n==========================================================================================\nWordPredictionLSTMModel                  [16, 6600, 256]           --\n├─Embedding: 1-1                         [16, 256, 256]            1,689,600\n├─LSTM: 1-2                              [16, 256, 1024]           30,441,472\n├─Sequential: 1-3                        [16, 256, 6600]           --\n│    └─Linear: 2-1                       [16, 256, 4096]           4,198,400\n│    └─LayerNorm: 2-2                    [16, 256, 4096]           8,192\n│    └─LeakyReLU: 2-3                    [16, 256, 4096]           --\n│    └─Dropout: 2-4                      [16, 256, 4096]           --\n│    └─Linear: 2-5                       [16, 256, 6600]           27,040,200\n==========================================================================================\nTotal params: 63,377,864\nTrainable params: 63,377,864\nNon-trainable params: 0\nTotal mult-adds (G): 125.22\n==========================================================================================\nInput size (MB): 0.03\nForward/backward pass size (MB): 526.65\nParams size (MB): 253.51\nEstimated Total Size (MB): 780.19\n==========================================================================================\n","output_type":"stream"}]},{"cell_type":"code","source":"class LitWordPredictor(pl.LightningModule):\n    def __init__(self, model):\n        super().__init__()\n        self.model = model\n        self.criterion = nn.CrossEntropyLoss(ignore_index=0)\n        self.accuracy1 = MulticlassAccuracy(num_classes=model.vocab_size, average='micro', ignore_index=0, top_k=1)\n        self.accuracy5 = MulticlassAccuracy(num_classes=model.vocab_size, average='micro', ignore_index=0, top_k=5)\n        self.lr = 3e-4 # 6.3e-4\n    #\n    \n    def forward(self, x):\n        return self.model(x)\n    #\n\n    def complete_sentence(self, input, tok, max_tokens, stop_token):\n        self.model.eval()\n        ids = tok.encode(input).ids\n        ids = torch.tensor(ids, device=self.device).unsqueeze(0)\n        for i in range(max_tokens):\n            y = self.model(ids)\n            y = y[:,:,-1]\n            y = y.argmax(dim=1).reshape(1, 1)\n            ids = torch.cat([ids, y], dim=1)\n            if y.item() == stop_token:\n                break\n            #\n        #\n        return ids\n    #\n    \n    def get_completion_probability(self, input, completion, tok):\n        self.model.eval()\n        ids = tok.encode(input).ids\n        ids = torch.tensor(ids, device=self.device).unsqueeze(0)\n        completion_ids = torch.tensor(tok.encode(completion).ids, device=self.device).unsqueeze(0)\n        # print(\"completion_ids:\", completion_ids)\n        \n        # probs below is the probability that the token at that location\n        # completes the sentence (in ids) so far.\n        probs = []\n        for i in range(completion_ids.size(1)):\n            # print(f\"i = {i}\")\n            y = self.model(ids)\n            y = y[0,:,-1].softmax(dim=0)\n            # prob is the probability of this completion.\n            prob = y[completion_ids[0,i]]\n            probs.append(prob)\n            # print(ids.shape, completion_ids[:,i:i+1].shape)\n            ids = torch.cat([ids, completion_ids[:,i:i+1]], dim=1)\n        #\n        return torch.tensor(probs)\n    #\n\n#\n\nx = torch.randint(0, VOCAB_SIZE-1, (5, 256))\n\nmodel = WordPredictionLSTMModel(\n    num_embed=VOCAB_SIZE, embed_dim=512, pad_idx=0, lstm_hidden_dim=786, lstm_num_layers=1, output_dim=VOCAB_SIZE, dropout=0.5,\n)\nprint(\"LSTM Model Summary\")\nprint(summary(model))\n\nprint(\"\")\n\nmlit = LitWordPredictor(model)\nmodel_type = \"lstm\"\nload_from_checkpoint_if_possible(mlit, model_type)\n\ny = mlit(x)\nprint(x.shape, y.shape)\ndel x, y\n\ndef complete_sentences(tok, mlit):\n    stop_token = tok.encode('\\n').ids[0]\n    sentences = [\n        \"Hello George! It feels like\",\n        \"Finally, an opening\",\n        \"I think I can make\",\n        \"Will you be able\",\n        \"Do you think we\",\n        \"The ice-cream truck\",\n        \"Good morning George!\",\n        \"Have a great\",\n        \"Usually, when one notices\",\n    ]\n\n    for s in sentences:\n        completion = mlit.complete_sentence(s, tok, max_tokens=20, stop_token=stop_token)\n        completion = completion[0]\n        # print(completion)\n        decoded = tok.decode(completion.tolist()).strip()\n        print(f\"[{s}] => {decoded}\")\n    #\n#\n\ndef word_completion_probabilities(tok, mlit):\n    sc = [\n        (\"That ice-cream looks\", (\"real\", \"absolutely\", \"really\", \"delicious\", \"atrocious\", \"paper\", \"fish\")),\n        (\"Since we're heading\", (\"toward\", \"away\", \"death\", \"birth\", \"both\", \"against\", \"bubble\")),\n        (\"Did I make\", (\"good\", \"a\", \"the\", \"food\", \"flower\", \"pencil\", \"color\", \"colour\", \"house\")),\n        (\"We want a candidate\", (\"that\", \"with\", \"which\", \"experience\", \"school\", \"more\", \"less\")),\n        (\"This is the definitive guide to the\", (\"complete\", \"illustrated\", \"extravagant\", \"miniscule\", \"wrapper\", \"rapper\", \"the\", \"sentence\")),\n        (\"Please can you\", (\"check\", \"confirm\", \"envelope\", \"laptop\", \"options\", \"cordon\", \"cease\", \"cradle\", \"corolla\")),\n        \n        #\n        (\"I think\", (\"I've\", \"ice\", \"Oct\")),\n        (\"Please\", (\"cab\", \"can\")),\n        (\"I've scheduled this\", (\"messing\", \"meeting\")),\n    ]\n\n    for s, cs in sc:\n        print(\"\")\n        candidates = []\n        for c in cs:\n            probs = mlit.get_completion_probability(s, \" \" + c, tok)\n            candidates.append((probs.prod(), c))\n        #\n        candidates = sorted(candidates, reverse=True)\n        for c in candidates:\n            print(f\"[{s}] [{c[1]}] = {c[0]:.5f}\")\n        #\n    #\n#\n\ncomplete_sentences(tok, mlit)\nword_completion_probabilities(tok, mlit)","metadata":{"execution":{"iopub.status.busy":"2023-08-18T20:55:23.054442Z","iopub.execute_input":"2023-08-18T20:55:23.055309Z","iopub.status.idle":"2023-08-18T20:55:31.634254Z","shell.execute_reply.started":"2023-08-18T20:55:23.055262Z","shell.execute_reply":"2023-08-18T20:55:31.632999Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n  warnings.warn(\"dropout option adds dropout after all but last \"\n","output_type":"stream"},{"name":"stdout","text":"LSTM Model Summary\n=================================================================\nLayer (type:depth-idx)                   Param #\n=================================================================\nWordPredictionLSTMModel                  --\n├─Embedding: 1-1                         3,379,200\n├─LSTM: 1-2                              4,087,200\n├─Sequential: 1-3                        --\n│    └─Linear: 2-1                       2,474,328\n│    └─LayerNorm: 2-2                    6,288\n│    └─LeakyReLU: 2-3                    --\n│    └─Dropout: 2-4                      --\n│    └─Linear: 2-5                       20,757,000\n=================================================================\nTotal params: 30,704,016\nTrainable params: 30,704,016\nNon-trainable params: 0\n=================================================================\n\nLoaded lstm model from location: /kaggle/input/2-lstm-model-for-next-word-checking/lstm_mlit_best.pt\ntorch.Size([5, 256]) torch.Size([5, 6600, 256])\n[Hello George! It feels like] => Hello George! It feels like a great place to go.\n[Finally, an opening] => Finally, an opening of the newly created a newly-signed version of the newly-signed F\n[I think I can make] => I think I can make a difference in the way you want to do it.\n[Will you be able] => Will you be able to do it?\n[Do you think we] => Do you think we can’t get the best of the day?\n[The ice-cream truck] => The ice-cream truck, and the other half of the day, the first time in the summer, the first time in\n[Good morning George!] => Good morning George!\n[Have a great] => Have a great day!\n[Usually, when one notices] => Usually, when one notices of the same thing, it is not a good idea to use the same thing.\n\n[That ice-cream looks] [really] = 0.00709\n[That ice-cream looks] [delicious] = 0.00264\n[That ice-cream looks] [absolutely] = 0.00122\n[That ice-cream looks] [real] = 0.00031\n[That ice-cream looks] [fish] = 0.00004\n[That ice-cream looks] [paper] = 0.00001\n[That ice-cream looks] [atrocious] = 0.00000\n\n[Since we're heading] [toward] = 0.01052\n[Since we're heading] [away] = 0.00344\n[Since we're heading] [against] = 0.00035\n[Since we're heading] [both] = 0.00009\n[Since we're heading] [death] = 0.00000\n[Since we're heading] [bubble] = 0.00000\n[Since we're heading] [birth] = 0.00000\n\n[Did I make] [a] = 0.22704\n[Did I make] [the] = 0.06622\n[Did I make] [good] = 0.00190\n[Did I make] [food] = 0.00020\n[Did I make] [color] = 0.00007\n[Did I make] [house] = 0.00006\n[Did I make] [colour] = 0.00002\n[Did I make] [pencil] = 0.00001\n[Did I make] [flower] = 0.00000\n\n[We want a candidate] [with] = 0.03209\n[We want a candidate] [that] = 0.02145\n[We want a candidate] [experience] = 0.00097\n[We want a candidate] [which] = 0.00094\n[We want a candidate] [more] = 0.00010\n[We want a candidate] [less] = 0.00007\n[We want a candidate] [school] = 0.00003\n\n[This is the definitive guide to the] [the] = 0.00089\n[This is the definitive guide to the] [complete] = 0.00047\n[This is the definitive guide to the] [sentence] = 0.00006\n[This is the definitive guide to the] [rapper] = 0.00001\n[This is the definitive guide to the] [illustrated] = 0.00001\n[This is the definitive guide to the] [extravagant] = 0.00000\n[This is the definitive guide to the] [wrapper] = 0.00000\n[This is the definitive guide to the] [miniscule] = 0.00000\n\n[Please can you] [check] = 0.00502\n[Please can you] [confirm] = 0.00488\n[Please can you] [cease] = 0.00002\n[Please can you] [cradle] = 0.00000\n[Please can you] [laptop] = 0.00000\n[Please can you] [envelope] = 0.00000\n[Please can you] [options] = 0.00000\n[Please can you] [cordon] = 0.00000\n[Please can you] [corolla] = 0.00000\n\n[I think] [I've] = 0.00087\n[I think] [ice] = 0.00001\n[I think] [Oct] = 0.00000\n\n[Please] [can] = 0.00428\n[Please] [cab] = 0.00000\n\n[I've scheduled this] [meeting] = 0.00077\n[I've scheduled this] [messing] = 0.00000\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}