{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ca0e6bc4",
   "metadata": {},
   "source": [
    "# Pairwise cosine similarity of a tensor\n",
    "\n",
    "How can we easily compute the pairwise cosine similarity between every pair of\n",
    "elements in a batch of vectors?\n",
    "\n",
    "The input is a 2-dimensional tensor, with the first dimension being the batch\n",
    "element (i.e. element index), and the second dimension being the vector (i.e.\n",
    "the value).\n",
    "\n",
    "The original idea comes from this post https://github.com/pytorch/pytorch/issues/48306\n",
    "This notebook is merely trying to disect the terse notation and explain what's\n",
    "going on under the hood.\n",
    "\n",
    "Terse notation:\n",
    "\n",
    "```\n",
    "cosine_similarity(x[:,:,None], x.t()[None,:,:])\n",
    "```\n",
    "\n",
    "In this notebook, we use a slightly different notation, which is the following:\n",
    "\n",
    "```\n",
    "cosine_similarity(x[None,:,:], x[:,None,:], dim=-1)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "328ec250",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "b9466a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = torch.manual_seed(21)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72f2350e",
   "metadata": {},
   "source": [
    "## Simple usage of cosine_similarity()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "14fbc61d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 4])\n"
     ]
    }
   ],
   "source": [
    "x, y = torch.randn(10, 4, 5), torch.randn(10, 4, 5)\n",
    "print(F.cosine_similarity(x, y, dim=2).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a8d5c4e",
   "metadata": {},
   "source": [
    "## Unsqueeze to add a dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "e1203ebf",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-1.2756,  1.1559, -0.0660]) torch.Size([3])\n",
      "tensor([[-1.2756,  1.1559, -0.0660]]) torch.Size([1, 3])\n",
      "tensor([[-1.2756],\n",
      "        [ 1.1559],\n",
      "        [-0.0660]]) torch.Size([3, 1])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(3)\n",
    "# Indexing with None does the same thing as unsqueezing the tensor\n",
    "# at that dimension. After this indexing operation, the tensors\n",
    "# x_row_dup and x_col_dup will have 1 additional dimension at\n",
    "# dimensions 0 and 1 respectively.\n",
    "x_row_dup, x_col_dup = x[None,:], x[:,None]\n",
    "\n",
    "print(x, x.shape)\n",
    "print(x_row_dup, x_row_dup.shape)\n",
    "print(x_col_dup, x_col_dup.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9e11683",
   "metadata": {},
   "source": [
    "## Expand the tensor at the newly added dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "b0ed2102",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x stretched across rows\n",
      "-----------------------\n",
      "tensor([[-1.2756,  1.1559, -0.0660],\n",
      "        [-1.2756,  1.1559, -0.0660],\n",
      "        [-1.2756,  1.1559, -0.0660]]) torch.Size([3, 3])\n",
      "\n",
      "x stretched across columns\n",
      "--------------------------\n",
      "tensor([[-1.2756, -1.2756, -1.2756],\n",
      "        [ 1.1559,  1.1559,  1.1559],\n",
      "        [-0.0660, -0.0660, -0.0660]]) torch.Size([3, 3])\n"
     ]
    }
   ],
   "source": [
    "x_row_dup, x_col_dup = x_row_dup.expand(3, 3), x_col_dup.expand(3, 3)\n",
    "\n",
    "print(\"x stretched across rows\")\n",
    "print(\"-----------------------\")\n",
    "print(x_row_dup, x_row_dup.shape)\n",
    "print(\"\")\n",
    "print(\"x stretched across columns\")\n",
    "print(\"--------------------------\")\n",
    "print(x_col_dup, x_col_dup.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1040ba16",
   "metadata": {},
   "source": [
    "## Compute pairwise cosine similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "53703e13",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1., -1.,  1.],\n",
      "        [-1.,  1., -1.],\n",
      "        [ 1., -1.,  1.]])\n"
     ]
    }
   ],
   "source": [
    "# Add a dummy dimension at the end so that we can perform cosine\n",
    "# similarity on that last dimension.\n",
    "x_row_dup = x_row_dup.reshape(3, 3, 1)\n",
    "x_col_dup = x_col_dup.reshape(3, 3, 1)\n",
    "x_cosine_similarity = F.cosine_similarity(x_row_dup, x_col_dup, dim=-1)\n",
    "print(x_cosine_similarity)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb01cd38",
   "metadata": {},
   "source": [
    "Turns out that the cosine similarity of 2 vectors of size 1 is always 1.\n",
    "\n",
    "That's because a single element vector has an angle of 0 degree and no rotation\n",
    "of vectors is possible in a 1 dimensional space.\n",
    "\n",
    "Hence 2 vectors with different magnitudes have the same angle between them.\n",
    "\n",
    "Let's try the same thing with a vector of size 2 instead of 1.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2ba7b75",
   "metadata": {},
   "source": [
    "## Cosine similarity of a batch of vectors\n",
    "\n",
    "Our batch has 3 vectors, each of size 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "03d528da",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.8099, 1.0222],\n",
      "        [0.6217, 0.6769],\n",
      "        [0.9647, 0.8141]]) torch.Size([3, 2])\n",
      "tensor([[[1.8099, 1.0222],\n",
      "         [0.6217, 0.6769],\n",
      "         [0.9647, 0.8141]]]) torch.Size([1, 3, 2])\n",
      "tensor([[[1.8099, 1.0222]],\n",
      "\n",
      "        [[0.6217, 0.6769]],\n",
      "\n",
      "        [[0.9647, 0.8141]]]) torch.Size([3, 1, 2])\n",
      "\n",
      "x with unsqueezed row dimension\n",
      "[( 1.8099, 1.0222), ( 0.6217, 0.6769), ( 0.9647, 0.8141)]\n",
      "\n",
      "x with unsqueezed column dimension\n",
      "[( 1.8099, 1.0222)]\n",
      "[( 0.6217, 0.6769)]\n",
      "[( 0.9647, 0.8141)]\n"
     ]
    }
   ],
   "source": [
    "def str_pair(x):\n",
    "    \"\"\"Returns a readable (converted to string) tuple of integers\n",
    "    from a tensor 'x' with exactly 2 elements.\n",
    "    \"\"\"\n",
    "    s0, s1 = \"\" if x[0] < 0 else \" \", \"\" if x[1] < 0 else \" \"\n",
    "    return f\"({s0}{x[0]:.4f},{s1}{x[1]:.4f})\"\n",
    "\n",
    "def display_3d_tensor(x):\n",
    "    \"\"\"Displays a 3d tensor with the last dimension having value 2 as\n",
    "    a 2d matix of tuples for easy visualization.\n",
    "    \"\"\"\n",
    "    assert len(x.size()) == 3\n",
    "    assert x.size(2) == 2\n",
    "    for i in range(x.size(0)):\n",
    "        elements = []\n",
    "        for j in range(x.size(1)):\n",
    "            elements.append(str_pair(x[i][j].tolist()))\n",
    "        # end for j\n",
    "        print(f\"[{', '.join(elements)}]\")\n",
    "    # end for i\n",
    "# end def\n",
    "\n",
    "\n",
    "x = torch.randn(3, 2)\n",
    "x_row_dup, x_col_dup = x[None,:,:], x[:,None,:]\n",
    "\n",
    "print(x, x.shape)\n",
    "print(x_row_dup, x_row_dup.shape)\n",
    "print(x_col_dup, x_col_dup.shape)\n",
    "\n",
    "# Let's pretty print these tensors. Each element of the 2d matrix is a\n",
    "# tensor with 2 elements (a pair of values).\n",
    "\n",
    "print(\"\\nx with unsqueezed row dimension\")\n",
    "display_3d_tensor(x_row_dup)\n",
    "print(\"\\nx with unsqueezed column dimension\")\n",
    "display_3d_tensor(x_col_dup)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d5240d9",
   "metadata": {},
   "source": [
    "## Stretch the tensors along row and column using .expand(...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "f693b89e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x stretched across rows\n",
      "-----------------------\n",
      "[( 1.8099, 1.0222), ( 0.6217, 0.6769), ( 0.9647, 0.8141)]\n",
      "[( 1.8099, 1.0222), ( 0.6217, 0.6769), ( 0.9647, 0.8141)]\n",
      "[( 1.8099, 1.0222), ( 0.6217, 0.6769), ( 0.9647, 0.8141)]\n",
      "\n",
      "x stretched across columns\n",
      "--------------------------\n",
      "[( 1.8099, 1.0222), ( 1.8099, 1.0222), ( 1.8099, 1.0222)]\n",
      "[( 0.6217, 0.6769), ( 0.6217, 0.6769), ( 0.6217, 0.6769)]\n",
      "[( 0.9647, 0.8141), ( 0.9647, 0.8141), ( 0.9647, 0.8141)]\n"
     ]
    }
   ],
   "source": [
    "# Now, lets expand the tensors in-place to stretch them across rows and columns.\n",
    "x_row_dup, x_col_dup = x_row_dup.expand(3, 3, 2), x_col_dup.expand(3, 3, 2)\n",
    "\n",
    "# and pretty-print them so that the 2d-matrix of a tuple (pair) of elements\n",
    "# representation becomes clear.\n",
    "print(\"x stretched across rows\")\n",
    "print(\"-----------------------\")\n",
    "display_3d_tensor(x_row_dup)\n",
    "print(\"\")\n",
    "print(\"x stretched across columns\")\n",
    "print(\"--------------------------\")\n",
    "display_3d_tensor(x_col_dup)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04fba5c6",
   "metadata": {},
   "source": [
    "## Pairwise cosine similarity on expanded tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "19df3f0e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.0000, 0.9512, 0.9826],\n",
      "        [0.9512, 1.0000, 0.9920],\n",
      "        [0.9826, 0.9920, 1.0000]])\n"
     ]
    }
   ],
   "source": [
    "# Since each value of the 2d matrix is already\n",
    "# multi-dimensional, we don't need to add a dummy\n",
    "# dimension at the end of the tensors.\n",
    "x_cosine_similarity = F.cosine_similarity(x_row_dup, x_col_dup, dim=-1)\n",
    "print(x_cosine_similarity)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fef8ab1",
   "metadata": {},
   "source": [
    "## Pairwise cosine similarity using broadcasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "bb508c52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.0000, 0.9512, 0.9826],\n",
      "        [0.9512, 1.0000, 0.9920],\n",
      "        [0.9826, 0.9920, 1.0000]])\n"
     ]
    }
   ],
   "source": [
    "# Now that we know how to compute the self-cosine similarity of every\n",
    "# vector in an array of vectors, let's do the same thing using\n",
    "# PyTorch's broadcasting semantics (i.e. without an explicit call\n",
    "# to .expand(...)).\n",
    "x_row_dup, x_col_dup = x[None,:,:], x[:,None,:]\n",
    "x_cosine_similarity = F.cosine_similarity(x_row_dup, x_col_dup, dim=-1)\n",
    "\n",
    "# This should print the same matrix as above.\n",
    "print(x_cosine_similarity)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2e4f114",
   "metadata": {},
   "source": [
    "## Links\n",
    "\n",
    "* https://stackoverflow.com/questions/69797614/indexing-a-tensor-with-none-in-pytorch\n",
    "* https://discuss.pytorch.org/t/pairwise-cosine-distance/30961\n",
    "* https://github.com/pytorch/pytorch/issues/48306\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
